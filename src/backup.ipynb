{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd8819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "target = 'default_flag'\n",
    "feature = ['loan_amnt']\n",
    "params = {\n",
    "    \"featuresCol\": \"features_col\",\n",
    "    \"labelCol\": \"target\",\n",
    "    # \"predictionCol\": \"prediction\",\n",
    "    \"probabilityCol\": \"probability\",\n",
    "    # \"rawPredictionCol\": \"rawPrediction\",\n",
    "    \"maxDepth\": 30,\n",
    "    \"maxBins\": 100,\n",
    "    # \"minInstancesPerNode\": 0.1,\n",
    "    # \"minInfoGain\": 0.0,\n",
    "    # \"impurity\": \"gini\",\n",
    "    # \"seed\": 42,\n",
    "}\n",
    "\n",
    "target_indexer = StringIndexer(inputCol=\"default_flag\", outputCol=\"target\")\n",
    "feature_assembler = VectorAssembler(inputCols=feature, outputCol=\"features_col\")\n",
    "pipeline = Pipeline(stages = [target_indexer, feature_assembler])\n",
    "pipeline_model = pipeline.fit(data_nulls_excluded)\n",
    "training_data = pipeline_model.transform(data_nulls_excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09963c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Window.rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "undersample = training_data\\\n",
    "    .groupBy(\"target\")\\\n",
    "    .agg(count(lit(1)).alias(\"count\"))\\\n",
    "    .withColumn(\"percentage\", \n",
    "                F.col(\"count\") / \n",
    "                sum(\"count\").over(w1))\\\n",
    "    .withColumn(\"undersample\", \n",
    "                max(when(F.col(\"target\")==1, F.col(\"percentage\"))).over(w1) /\n",
    "                    max(when(F.col(\"target\")==0, F.col(\"percentage\"))).over(w1))\\\n",
    "    .select(collect_list(\"undersample\")).first()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "defaulted_df = training_data\\\n",
    "    .sampleBy(\"target\", fractions={0: undersample, 1: 1.0}, seed=0)\n",
    "\n",
    "defaulted_df\\\n",
    ".groupBy(\"target\")\\\n",
    ".agg(count(lit(1)))\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol=\"target\", \n",
    "                             featuresCol=\"features_col\",\n",
    "                             minInfoGain=0.0,\n",
    "                             maxDepth=7,\n",
    "                             maxBins=100,\n",
    "                             impurity='gini')\n",
    "model = dtc.fit(defaulted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb542431",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max depth:\", model.getMaxDepth())\n",
    "print(\"Max Bins:\", model.getMaxBins())\n",
    "print(\"Min weight:\", model.getMinWeightFractionPerNode())\n",
    "print(\"Min instances:\", model.getMinInstancesPerNode())\n",
    "print(\"Min info gain:\", model.getMinInfoGain())\n",
    "print(model.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbeaabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save(f\"{output_path}tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fae422",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df = spark.read.parquet(f\"{output_path}tree/data\")\n",
    "\n",
    "tree_df\\\n",
    ".withColumn(\"impurity0\", F.get(F.col(\"impurityStats\"),0))\\\n",
    ".withColumn(\"impurity1\", F.get(F.col(\"impurityStats\"),1))\\\n",
    ".withColumn(\"med_impurity\", (F.col(\"impurity0\") + F.col(\"impurity1\")))\\\n",
    ".where(F.col(\"split.featureIndex\")==0)\\\n",
    ".withColumn(\"n_thresholds\")\\\n",
    ".orderBy(F.col(\"med_impurity\").desc())\\\n",
    ".show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
